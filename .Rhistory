important_vars_hs <- names(star_hs_x[important_vars_hs])
n <- nrow(star_hs_1)
star_hs_1 <- star_hs |>
filter(!is.na(hsgpaoverall))
# Define treatment and outcome vectors
W <- star_hs_1$W
outcome <- hs_outcomes[1]
Y <- star_hs_1 |>
pull(outcome) |>
as.vector()
star_hs_x <- star_hs_1 |>
select(-W, -stdntid) |>
select(!contains(c(hs_outcomes)))
set.seed(123)
n <- nrow(star_hs_1)
# Number of rankings predictions will be ranked on
num.rankings <- 5
# Prepare for data.splitting
# Assign a fold number to each observation.
# The argument 'clusters' in the next step will mimic K-fold cross-fitting.
num.folds <- 10
folds <- sort(seq(n) %% num.folds) + 1
# Estimate a causal forest
forest <- causal_forest(X = star_hs_x, Y=Y, W=W, W.hat=mean(W),
clusters = star_hs_x$hsid,
min.node.size = 5)
#histogram of estimated HTE via causal forest
hist(predict(forest)$predictions)
#ate predictions
hs_ate <- average_treatment_effect(forest, target.sample = "overlap", method = "AIPW")
hs_ate_se <- hs_ate[2]
hs_ate <- hs_ate[1]
#not statistically significant
print(paste0("95% CI: ", round(hs_ate,2),
" +/- ", round(1.96 * hs_ate_se, 2)))
#calibrate forest
#mean.forest.prediction is statistically insignificant but if it wasn't i think the coef of 3.73 means way underfit
#differential.forest.prediction statistically significant and about 1, so there is heterogeneity
test_calibration(forest)
#important contributing variables in causal forest
var_importance <- variable_importance(forest) |>
as_tibble() |>
mutate(n_col = row_number()) |>
arrange(-V1)
important_vars_hs <- var_importance %>%
slice(1:10) %>%
pull(n_col)
important_vars_hs <- names(star_hs_x[important_vars_hs])
forest <- causal_forest(X=star_g7_x, Y=Y, W=W, W.hat=mean(W),
clusters = star_g7_math$g7schid,
min.node.size = 5)
star_g7_math <- star_g7 |>
filter(!is.na(g7tmathss))
# Define treatment and outcome vectors
W <- star_g7_math$W
outcome <- g7_outcomes[2]
Y <- star_g7_math |>
pull(outcome) |>
as.vector()
star_g7_x <- star_g7_math |>
select(-W, -stdntid, -gkclasstype, -g1classtype, -g2classtype, -g3classtype, -cmpstype,-cmpsdura,
-yearssmall, yearsstar, -gk_smallclass, -g1_smallclass, -g2_smallclass, -g3_smallclass) |>
select(!starts_with(c("birth", "flagsgk"))) |>
select(!contains(c(g7_outcomes)))
n <-nrow(star_g7_math)
# Number of rankings predictions will be ranked on
num.rankings <- 5
# Prepare for data.splitting
# Assign a fold number to each observation.
# The argument 'clusters' in the next step will mimic K-fold cross-fitting.
num.folds <- 10
folds <- sort(seq(n) %% num.folds) + 1
# Estimate a causal forest
forest <- causal_forest(X=star_g7_x, Y=Y, W=W, W.hat=mean(W),
clusters = star_g7_math$g7schid,
min.node.size = 5)
forest <- causal_forest(X=star_g7_x, Y=Y, W=W, W.hat=mean(W),
clusters = star_g7_math$gkschid,
min.node.size = 5)
View(star)
star$schid_yr1star <- case_when(star$flagsgk == 1 ~ star$gkschid,
((star$flagsgk == 0) & (star$flagsg1 == 1)) ~ star$g1schid,
((star$flagsgk == 0) & (star$flagsg1 == 0) & (star$flagsg2 == 1)) ~ star$g2schid,
((star$flagsgk == 0) & (star$flagsg1 == 0) & (star$flagsg2 == 0) & (star$flagsg3 == 1)) ~ star$g3schid)
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(haven)
library(splines)
library(glmnet)
library(grf)
library(recipes)
library(fastDummies)
library(haven)
library(pacman)
library(readr)
library(janitor)
# Set working directory
options(stringAsFactors=FALSE)
setwd("~/Documents/Github/Econ293_Final_Project/")
star <- read_sav("./data/STAR_Students.sav")
names(star) <- tolower(names(star))
# creating indicator variable for treatment group; 1 = in small class for at least a year in grades kinder - 3rd
star <- star %>%
mutate(W = if_else(gkclasstype==1 | g1classtype==1 | g2classtype==1 | g3classtype==1, 1, 0)) %>%
mutate(W = if_else(is.na(W), 0, W))
# creating indicators for what year students were in small classes. 1 = in small class, 0 = not in small class
star$gk_smallclass <- case_when(star$gkclasstype == 1 ~ 1,
((star$gkclasstype == 2) | (star$gkclasstype == 3)) ~ 0)
star$g1_smallclass <- case_when(star$g1classtype == 1 ~ 1,
((star$g1classtype == 2) | (star$g1classtype == 3)) ~ 0)
star$g2_smallclass <- case_when(star$g2classtype == 1 ~ 1,
((star$g2classtype == 2) | (star$g2classtype == 3)) ~ 0)
star$g3_smallclass <- case_when(star$g3classtype == 1 ~ 1,
((star$g3classtype == 2) | (star$g3classtype == 3)) ~ 0)
# creating school id variable for school student was in in their first year of STAR
star$schid_yr1star <- case_when(star$flagsgk == 1 ~ star$gkschid,
((star$flagsgk == 0) & (star$flagsg1 == 1)) ~ star$g1schid,
((star$flagsgk == 0) & (star$flagsg1 == 0) & (star$flagsg2 == 1)) ~ star$g2schid,
((star$flagsgk == 0) & (star$flagsg1 == 0) & (star$flagsg2 == 0) & (star$flagsg3 == 1)) ~ star$g3schid)
# Load K-3 school level data
k3_schools <- read_sav("./data/STAR_K-3_Schools.sav")
k3_schools <- k3_schools %>% clean_names()
# create a duplicate of school data to merge into student data for each year of k-3
k3_k_schools <- k3_schools
colnames(k3_k_schools) <- paste(colnames(k3_k_schools), "k", sep = "_")
k3_g1_schools <- k3_schools
colnames(k3_g1_schools) <- paste(colnames(k3_g1_schools), "g1", sep = "_")
k3_g2_schools <- k3_schools
colnames(k3_g2_schools) <- paste(colnames(k3_g2_schools), "g2", sep = "_")
k3_g3_schools <- k3_schools
colnames(k3_g3_schools) <- paste(colnames(k3_g3_schools), "g3", sep = "_")
# Merge-in school data separately for each grade the student was in K-3
star <- star %>%
left_join(k3_k_schools, by = c("gkschid" = "schid_k")) %>%
left_join(k3_g1_schools, by = c("g1schid" = "schid_g1")) %>%
left_join(k3_g2_schools, by = c("g2schid" = "schid_g2")) %>%
left_join(k3_g3_schools, by = c("g3schid" = "schid_g3"))
# Drop observations which have key variables missing
na_counts = map(star, ~sum(is.na(.)))
#SHORT TERM OUTCOMES
# Define short-term: grade 3 outcomes
short_term_outcomes <- c("g3treadss", "g3tmathss", "g3readbsraw",
"g3mathbsraw")
# List of variables to drop whe predicting short-term outcomes
drop_for_short_term <- c("g3tlistss", "g3sciencess", "g3socialsciss", "g3spellss",
"g3vocabss", "g3mathcomputss", "g3mathnumconcss",
"g3mathapplss", "g3wordskillss", "g3mathbsobjraw",
"g3mathbsobjpct", "g3readbsobjpct")
# Drop the other grade 3 outcomes from the list above
star_short_term <- star[,!(names(star) %in% drop_for_short_term)]
# Drop future (beyond grade 3) outcomes and characteristics
star_short_term <- star_short_term %>%
select(!starts_with(c("g4", "g5", "g6", "g7", "g8" , "hs")))
# LONG TERM OUTCOMES
# 7TH GRADE
# Define one long term outcome: 7th grade outcomes
g7_outcomes <- c("g7treadss", "g7tmathss")
# List of variables to drop when predicting 7th grade outcomes
drop_for_g7 <- c("g7tlangss","g7tbattss", "g7sciencess", "g7socialsciss",
"g7readcomprehss", "g7spellss", "g7vocabss", "g7mathcomputss",
"g7mathconcapplss", "g7langexpss", "g7langmechss",
"g7studyskillss", "g7readbsobjraw", "g7mathbsobjraw")
# Drop the other grade 7 outcomes from the list above
star_g7 <- star[,!(names(star) %in% drop_for_g7)]
# Drop future (beyond grade 7) outcomes and characteristics)
star_g7 <- star_g7 |>
select(!starts_with(c("g8", "hs")))
# high school GPA
hs_outcomes <- c("hsgpaoverall")
#drop other HS GPA outcomes
drop_for_hs <- c("hsgpaflang", "hsgpamath", "hsgpascience")
# Drop the other HS GPA outcomes from the list above
star_hs <- star[,!(names(star) %in% drop_for_hs)]
star_g7_math <- star_g7 |>
filter(!is.na(g7tmathss))
# Define treatment and outcome vectors
W <- star_g7_math$W
outcome <- g7_outcomes[2]
Y <- star_g7_math |>
pull(outcome) |>
as.vector()
star_g7_x <- star_g7_math |>
select(-W, -stdntid, -gkclasstype, -g1classtype, -g2classtype, -g3classtype, -cmpstype,-cmpsdura, -yearssmall, yearsstar, -gk_smallclass, -g1_smallclass, -g2_smallclass, -g3_smallclass) |>
select(!starts_with(c("birth", "flagsgk"))) |>
select(!ends_with("schid"))
select(!contains(c(g7_outcomes)))
star_g7_math <- star_g7 |>
filter(!is.na(g7tmathss))
# Define treatment and outcome vectors
W <- star_g7_math$W
outcome <- g7_outcomes[2]
Y <- star_g7_math |>
pull(outcome) |>
as.vector()
star_g7_x <- star_g7_math |>
select(-W, -stdntid, -gkclasstype, -g1classtype, -g2classtype, -g3classtype, -cmpstype,-cmpsdura, -yearssmall, yearsstar, -gk_smallclass, -g1_smallclass, -g2_smallclass, -g3_smallclass) |>
select(!starts_with(c("birth", "flagsgk"))) |>
select(!ends_with("schid")) |>
select(!contains(c(g7_outcomes)))
View(star_g7_x)
star_g7_math <- star_g7 |>
filter(!is.na(g7tmathss))
# Define treatment and outcome vectors
W <- star_g7_math$W
outcome <- g7_outcomes[2]
Y <- star_g7_math |>
pull(outcome) |>
as.vector()
star_g7_x <- star_g7_math |>
select(-W, -stdntid, -gkclasstype, -g1classtype, -g2classtype, -g3classtype, -cmpstype,-cmpsdura, -yearssmall, yearsstar, -gk_smallclass, -g1_smallclass, -g2_smallclass, -g3_smallclass) |>
select(!starts_with(c("birth", "flag"))) |>
select(!ends_with("schid")) |>
select(!contains(c(g7_outcomes)))
bivariate_ols <- lm(g7tmathss ~ W
+ as.factor(gkschid)
+ as.factor(g1schid)
+ as.factor(g2schid)
+ as.factor(g3schid)
+ as.factor(g4schid)
+ as.factor(g5schid)
+ as.factor(g6schid)
+ as.factor(g7schid), data=star_g7_math)
summary(bivariate_ols)
bivariate_ols <- lm(g7tmathss ~ W
+ as.factor(schid_yr1star), data=star_g7_math)
summary(bivariate_ols)
set.seed(123)
n <-nrow(star_g7_math)
# Number of rankings predictions will be ranked on
num.rankings <- 5
# Prepare for data.splitting
# Assign a fold number to each observation.
# The argument 'clusters' in the next step will mimic K-fold cross-fitting.
num.folds <- 10
folds <- sort(seq(n) %% num.folds) + 1
# Estimate a causal forest
forest <- causal_forest(X=star_g7_x, Y=Y, W=W, W.hat=mean(W),
clusters = star_g7_math$schid_yr1star,
min.node.size = 5)
#histogram of estimated HTE via causal forest
hist(predict(forest)$predictions)
#estimated ATE
g7_ate_math <- average_treatment_effect(forest, target.sample = "overlap", method = "AIPW")
g7_ate_math_se <- g7_ate_math[2]
g7_ate_math <- g7_ate_math[1]
#not statistically significant
print(paste0("95% CI: ", round(g7_ate_math,2),
" +/- ", round(1.96 * g7_ate_math_se, 2)))
#important contributing variables in causal forest
var_importance <- variable_importance(forest) |>
as_tibble() |>
mutate(n_col = row_number()) |>
arrange(-V1)
important_vars_g7_math <- var_importance %>%
slice(1:10) %>%
pull(n_col)
important_vars_g7_math <- names(star_g7_x[important_vars_g7_math])
important_vars_g7_math
g7_math_hte <- test_calibration(forest)
g7_math_hte
star_g7_reading <- star_g7 |>
filter(!is.na(g7treadss))
# Define treatment and outcome vectors
W <- star_g7_reading$W
outcome <- g7_outcomes[1]
Y <- star_g7_reading |>
pull(outcome) |>
as.vector()
star_g7_x <- star_g7_reading |>
select(-W, -stdntid, -gkclasstype, -g1classtype, -g2classtype, -g3classtype, -cmpstype,-cmpsdura, -yearssmall, yearsstar, -gk_smallclass, -g1_smallclass, -g2_smallclass, -g3_smallclass) |>
select(!starts_with(c("birth", "flag"))) |>
select(!ends_with("schid")) |>
select(!contains(c(g7_outcomes)))
# primary analysis
bivariate_ols <- lm(g7treadss ~ W
+ as.factor(gkschid)
+ as.factor(g1schid)
+ as.factor(g2schid)
+ as.factor(g3schid)
+ as.factor(g4schid)
+ as.factor(g5schid)
+ as.factor(g6schid)
+ as.factor(g7schid), data=star_g7_reading)
summary(bivariate_ols)
n <-nrow(star_g7_reading)
# Number of rankings predictions will be ranked on
num.rankings <- 5
# Prepare for data.splitting
# Assign a fold number to each observation.
# The argument 'clusters' in the next step will mimic K-fold cross-fitting.
num.folds <- 10
folds <- sort(seq(n) %% num.folds) + 1
# Estimate a causal forest
forest <- causal_forest(X = star_g7_x, Y=Y, W=W,W.hat=mean(W),
clusters = star_g7_reading$schid_yr1star,
min.node.size = 5)
hist(predict(forest)$predictions)
g7_ate_reading <- average_treatment_effect(forest, target.sample = "overlap", method = "AIPW")
g7_ate_reading_se <- g7_ate_reading[2]
g7_ate_reading <- g7_ate_reading[1]
#not statistically significant
print(paste0("95% CI: ", round(g7_ate_reading,2),
" +/- ", round(1.96 * g7_ate_reading_se, 2)))
var_importance <- variable_importance(forest) |>
as_tibble() |>
mutate(n_col = row_number()) |>
arrange(-V1)
important_vars_g7_reading <- var_importance %>%
slice(1:10) %>%
pull(n_col)
important_vars_g7_reading<- names(star_g7_x[important_vars_g7_reading])
important_vars_g7_reading
forest$predictions
??grf
library(kableExtra)
#1st step :
#Create column vectors :
dataframe = data.frame(Regression = c(1,2,3), Causal_Forest = c(1,2,3), Regression = c(1,2,3), Causal_Forest = c(1,2,3), Regression = c(1,2,3), Causal_Forest = c(1,2,3), Regression = c(1,2,3), Causal_Forest = c(1,2,3), Regression = c(1,2,3), Causal_Forest = c(1,2,3), check.names = FALSE)
#2nd step : Set index
rownames(dataframe) <- c(“Effect Size”,“Std. Error”,“P-Value”)
#3rd step :
kbl(dataframe) %>%
kable_classic() %>%
add_header_above(c(” ” = 1, “Grade 3 Reading” = 2, “Grade 3 Math” = 2, “Grade 7 Reading” = 2, “Grade 7 Math” = 2, “High School” = 2))
library(pacman)
p_load(tidyverse, haven, readr, janitor, grf, labelled, plm, sandwich, lmtest, glue)
options(stringAsFactors=FALSE)
short_term_outcomes <- c("g1treadss", "g1tmathss", "g1wordskillss")
star_short_term <- star_short_term %>%
filter(!is.na(g1_smallclass)) %>%
mutate(W = if_else(g1_smallclass==1, 1, 0))
star_short_term <- star_short_term %>%
dplyr::select(-gkclasstype, -g1classtype, -g2classtype, -g3classtype, -cmpstype,
-yearssmall, -gk_smallclass, -g1_smallclass, -g2_smallclass, -g3_smallclass,
-yearsstar, -g1readbsraw, -g1mathbsraw, -g1readbsobjraw, -g1mathbsobjraw,
-g1readbsobjpct, -g1mathbsobjpct, -g1tchid, -gktchid, -g1promote, -cmpsdura)
# Causal Forest -----------------------------------------------------------
# Estimate a causal forest
forest <- causal_forest(X = star_short_term_x, Y=Y, W=W,
clusters = star_short_term_x$g1schid,
min.node.size = 5,
tune.parameters = "all",
seed = 20220524)
# Plot propensity scores
hist(forest$W.hat)
# Average treatment effect
average_treatment_effect(forest, method = "AIPW")
# Test for heterogeneous treatment effects
test_calibration(forest)
#
# Explore variable importance suggested by the causal forest
# var_importance <- variable_importance(forest) %>%
#   as_tibble() %>%
#   mutate(n_col = row_number()) %>%
#   arrange(-V1)
#
# important_vars <- var_importance %>%
#   slice(1:10) %>%
#   pull(n_col)
#
# test <- star_short_term_x[important_vars]
star_short_term_x <- star_short_term_x %>%
mutate(cate_estimate = predict(forest)$predictions)
hist(predict(forest)$predictions)
# ggplot(star_short_term_x, aes(race, g1freelunch, fill = cate_estimate)) +
#   geom_raster()
#
# star_short_term_x %>%
#   # group_by(race) %>%
#   # summarize(mean_cate = mean(cate_estimate)) %>%
#   # ungroup() %>%
#   ggplot(aes(x = factor(g1surban), y = cate_estimate)) +
#   geom_boxplot(aes(group = factor(g1surban)))
save(star_short_term_x, file = glue("./data/cate_estimates_short_term_{outcome}.rda"))
}
# Causal Forest -----------------------------------------------------------
# Estimate a causal forest
forest <- causal_forest(X = star_short_term_x, Y=Y, W=W,
clusters = star_short_term_x$g1schid,
min.node.size = 5,
tune.parameters = "all",
seed = 20220524)
# Plot propensity scores
hist(forest$W.hat)
# Average treatment effect
average_treatment_effect(forest, method = "AIPW")
# Test for heterogeneous treatment effects
test_calibration(forest)
#
# Explore variable importance suggested by the causal forest
# var_importance <- variable_importance(forest) %>%
#   as_tibble() %>%
#   mutate(n_col = row_number()) %>%
#   arrange(-V1)
#
# important_vars <- var_importance %>%
#   slice(1:10) %>%
#   pull(n_col)
#
# test <- star_short_term_x[important_vars]
star_short_term_x <- star_short_term_x %>%
mutate(cate_estimate = predict(forest)$predictions)
hist(predict(forest)$predictions)
# ggplot(star_short_term_x, aes(race, g1freelunch, fill = cate_estimate)) +
#   geom_raster()
#
# star_short_term_x %>%
#   # group_by(race) %>%
#   # summarize(mean_cate = mean(cate_estimate)) %>%
#   # ungroup() %>%
#   ggplot(aes(x = factor(g1surban), y = cate_estimate)) +
#   geom_boxplot(aes(group = factor(g1surban)))
save(star_short_term_x, file = glue("./data/cate_estimates_short_term_{outcome}.rda"))
}
linear_regression <- plm(g7tmathss ~ factor(W) + factor(race) + gender + g1surban + g1freelunch,
data = star_g7_math,
index = c("schid_yr1star"),
model = "within")
# print summary using robust standard errors
coeftest(linear_regression, vcov. = vcovHC, type = "HC1")
?plm
save(star_short_term_x, file = glue("./data/cate_estimates_short_term_{outcome}.rda"))
linear_regression <- plm(g7treadss ~ factor(W) + factor(race) + gender + g1surban + g1freelunch,
data = star_g7_math,
index = c("schid_yr1star"),
model = "within")
# print summary using robust standard errors
coeftest(linear_regression, vcov. = vcovHC, type = "HC1")
for (outcome in short_term_outcomes) {
# Drop observations with missing values for the outcome
star_short_term_1 <- star_short_term %>%
filter(!is.na(get(outcome)))
# Define outcome and treatment vectors
W <- star_short_term_1$W
Y <- star_short_term_1 %>% pull(outcome) %>% as.vector()
# Drop other covariates that are not useful
star_short_term_x <- star_short_term_1 %>%
dplyr::select(-W, -stdntid) %>%
dplyr::select(-contains(c(short_term_outcomes))) %>%
dplyr::select(-contains("classsize")) %>%
dplyr::select(-contains("flag")) %>%
dplyr::select(-gkschid, -schid_yr1star)
n <- nrow(star_short_term_1)
# Linear Regression -------------------------------------------------------
# Define a list of covariates manually inputed
covariates <- c("race", "gender", "birthyear", "g1surban", "g2surban",
"g2readbsraw", "g2motivraw", "g3surban",
"g3freelunch", "g3schid", "g3tyears", "g2tyear")
star_short_term_cov <- star_short_term_x %>%
dplyr::select(contains(c(covariates)))
linear_model_data <- star_short_term_x %>%
mutate(W = W,
y = Y) %>%
dplyr::select(W, y, race, gender, birthyear, g1surban,
g1freelunch, g1schid)
fe_model <- plm(y ~ factor(W) + factor(race) + gender + g1surban + g1freelunch,
data = linear_model_data,
index = c("g1schid"),
model = "within")
# print summary using robust standard errors
coeftest(fe_model, vcov. = vcovHC, type = "HC1")
# Causal Forest -----------------------------------------------------------
# Estimate a causal forest
forest <- causal_forest(X = star_short_term_x, Y=Y, W=W,
clusters = star_short_term_x$g1schid,
min.node.size = 5,
tune.parameters = "all",
seed = 20220524)
# Plot propensity scores
hist(forest$W.hat)
# Average treatment effect
average_treatment_effect(forest, method = "AIPW")
# Test for heterogeneous treatment effects
test_calibration(forest)
#
# Explore variable importance suggested by the causal forest
# var_importance <- variable_importance(forest) %>%
#   as_tibble() %>%
#   mutate(n_col = row_number()) %>%
#   arrange(-V1)
#
# important_vars <- var_importance %>%
#   slice(1:10) %>%
#   pull(n_col)
#
# test <- star_short_term_x[important_vars]
star_short_term_x <- star_short_term_x %>%
mutate(cate_estimate = predict(forest)$predictions)
hist(predict(forest)$predictions)
# ggplot(star_short_term_x, aes(race, g1freelunch, fill = cate_estimate)) +
#   geom_raster()
#
# star_short_term_x %>%
#   # group_by(race) %>%
#   # summarize(mean_cate = mean(cate_estimate)) %>%
#   # ungroup() %>%
#   ggplot(aes(x = factor(g1surban), y = cate_estimate)) +
#   geom_boxplot(aes(group = factor(g1surban)))
save(star_short_term_x, file = glue("./data/cate_estimates_short_term_{outcome}.rda"))
}
linear_regression <- plm(g7tmathss ~ factor(W) + factor(race) + gender,
data = star_g7_math,
index = c("schid_yr1star"),
model = "within")
adkfjaklds
linear_regression <- plm(g7tmathss ~ factor(W) + factor(race) + gender,
data = star_g7_math,
index = c("schid_yr1star"),
model = "within")
coeftest(linear_regression, vcov. = vcovHC, type = "HC1")
